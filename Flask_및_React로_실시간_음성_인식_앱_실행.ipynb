{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지 설치\n",
        "!pip install flask flask-cors flask-sock openai-whisper pyngrok soundfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b5FdQdYmVg2",
        "outputId": "901680cc-0554-478d-ef7b-ccb699f86394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Collecting flask-cors\n",
            "  Downloading flask_cors-6.0.0-py3-none-any.whl.metadata (961 bytes)\n",
            "Collecting flask-sock\n",
            "  Downloading flask_sock-0.7.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Collecting simple-websocket>=0.5.1 (from flask-sock)\n",
            "  Downloading simple_websocket-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Collecting wsproto (from simple-websocket>=0.5.1->flask-sock)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.4.26)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.5.1->flask-sock) (0.16.0)\n",
            "Downloading flask_cors-6.0.0-py3-none-any.whl (11 kB)\n",
            "Downloading flask_sock-0.7.0-py3-none-any.whl (4.0 kB)\n",
            "Downloading pyngrok-7.2.8-py3-none-any.whl (25 kB)\n",
            "Downloading simple_websocket-1.1.0-py3-none-any.whl (13 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803404 sha256=d70c3714978142296e2a6332e4f894a84b76352741d1aaa5517916a101a430fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: wsproto, pyngrok, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, simple-websocket, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, flask-sock, flask-cors, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed flask-cors-6.0.0 flask-sock-0.7.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 pyngrok-7.2.8 simple-websocket-1.1.0 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ngrok 인증 설정\n",
        "!ngrok authtoken 2wQlh1yhomkbcOTbhwOdNCzDx99_7jecQV8VibPuWQXnH9eVX  # 여기에 ngrok 인증 토큰을 입력하세요\n",
        "\n",
        "# ngrok 설치 확인\n",
        "!ngrok --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KI3IPHKmbWQ",
        "outputId": "fde105d8-3c40-4461-8c7b-9230fd40b554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "ngrok version 3.22.1\n",
            "pyngrok version 7.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프로젝트 디렉토리 구조 생성\n",
        "!mkdir -p ./www"
      ],
      "metadata": {
        "id": "nVrHKtfImmgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from flask import Flask, render_template\n",
        "from flask_cors import CORS\n",
        "from flask_sock import Sock\n",
        "import whisper\n",
        "import io\n",
        "\n",
        "app = Flask(__name__,\n",
        "    template_folder='./www',\n",
        "    static_folder='./www',\n",
        "    static_url_path='/'\n",
        ")\n",
        "CORS(app)  # 모든 도메인에서의 접근을 허용\n",
        "sock = Sock(app)\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@sock.route('/audio')\n",
        "def handle_audio(ws):\n",
        "    while True:\n",
        "        data = ws.receive()\n",
        "        if data is None:\n",
        "            break\n",
        "\n",
        "        audio_stream = io.BytesIO(data)\n",
        "        audio_stream.seek(0)  # 스트림의 시작으로 이동\n",
        "\n",
        "        try:\n",
        "            # 오디오 데이터를 .wav 파일로 저장\n",
        "            with open('received_audio.wav', 'wb') as f:\n",
        "                f.write(audio_stream.read())\n",
        "\n",
        "            # Whisper 모델에 .wav 파일을 전달하여 인식\n",
        "            result = model.transcribe('received_audio.wav')\n",
        "            ws.send(result['text'])\n",
        "        except Exception as e:\n",
        "            print(f'Error: {e}')\n",
        "            ws.send('Error processing audio')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=3000, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbN0zdbRm2eu",
        "outputId": "44d7d643-468e-4190-96f1-53644f72e3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile www/index.html\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Audio Recorder</title>\n",
        "    <script src=\"https://unpkg.com/react@17/umd/react.development.js\"></script>\n",
        "    <script src=\"https://unpkg.com/react-dom@17/umd/react-dom.development.js\"></script>\n",
        "    <script src=\"https://unpkg.com/@mui/material@5.0.0/umd/material-ui.development.js\"></script>\n",
        "    <script src=\"https://unpkg.com/@babel/standalone/babel.min.js\"></script>\n",
        "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css?family=Roboto:300,400,500,700&display=swap\" />\n",
        "    <link rel=\"stylesheet\" href=\"styles.css\">\n",
        "</head>\n",
        "<body>\n",
        "    <div id=\"root\"></div>\n",
        "    <script type=\"text/babel\" src=\"app.js\"></script>\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hby4Og0m4w_",
        "outputId": "8b91fd79-76c9-43a6-cb79-f15156e2ccb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing www/index.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile www/styles.css\n",
        "body {\n",
        "  margin: 0;\n",
        "  font-family: 'Roboto', sans-serif;\n",
        "}\n",
        "\n",
        ".container {\n",
        "  max-width: 800px;\n",
        "  margin: 0 auto;\n",
        "  padding: 16px;\n",
        "}\n",
        "\n",
        ".chat-bubble {\n",
        "  padding: 16px;\n",
        "  margin-bottom: 8px;\n",
        "  background-color: #f5f5f5;\n",
        "  border-radius: 4px;\n",
        "  word-break: break-word;\n",
        "}\n",
        "\n",
        ".transcription-container {\n",
        "  max-height: 300px;\n",
        "  overflow-y: auto;\n",
        "  margin-top: 16px;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vcjwxkkm8jE",
        "outputId": "a2370248-d989-4f24-b253-f0f4e16f29ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing www/styles.css\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile www/app.js\n",
        "const { useState, useRef, useEffect } = React;\n",
        "const {\n",
        "  AppBar, Toolbar, Typography, Button, Container, Box, Paper, TextField\n",
        "} = MaterialUI;\n",
        "\n",
        "function App() {\n",
        "  // 현재 접속한 URL을 기반으로 WebSocket URL 자동 생성\n",
        "  const getDefaultWebsocketUrl = () => {\n",
        "    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';\n",
        "    const host = window.location.host;\n",
        "    return `${protocol}//${host}/audio`;\n",
        "  };\n",
        "\n",
        "  const [isRecording, setIsRecording] = useState(false);\n",
        "  const [transcriptions, setTranscriptions] = useState([]);\n",
        "  const [websocketUrl, setWebsocketUrl] = useState(getDefaultWebsocketUrl());\n",
        "  const mediaRecorderRef = useRef(null);\n",
        "  const audioChunksRef = useRef([]);\n",
        "  const socketRef = useRef(null);\n",
        "\n",
        "  const handleWebSocketUrlChange = (event) => {\n",
        "    setWebsocketUrl(event.target.value);\n",
        "  };\n",
        "\n",
        "  const handleStartRecording = async () => {\n",
        "    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "    mediaRecorderRef.current = new MediaRecorder(stream);\n",
        "\n",
        "    mediaRecorderRef.current.ondataavailable = (event) => {\n",
        "      audioChunksRef.current.push(event.data);\n",
        "    };\n",
        "\n",
        "    mediaRecorderRef.current.onstop = () => {\n",
        "      sendAudioData();\n",
        "    };\n",
        "\n",
        "    mediaRecorderRef.current.start();\n",
        "    setIsRecording(true);\n",
        "  };\n",
        "\n",
        "  const handleStopRecording = () => {\n",
        "    if (mediaRecorderRef.current) {\n",
        "      mediaRecorderRef.current.stop();\n",
        "      setIsRecording(false);\n",
        "    }\n",
        "  };\n",
        "\n",
        "  const sendAudioData = () => {\n",
        "    const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });\n",
        "    const reader = new FileReader();\n",
        "    reader.onloadend = () => {\n",
        "      const audioArrayBuffer = reader.result;\n",
        "      if (socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {\n",
        "        socketRef.current.send(audioArrayBuffer);\n",
        "      }\n",
        "      audioChunksRef.current = [];\n",
        "    };\n",
        "    reader.readAsArrayBuffer(audioBlob);\n",
        "  };\n",
        "\n",
        "  const setupWebSocket = () => {\n",
        "    socketRef.current = new WebSocket(websocketUrl);\n",
        "\n",
        "    socketRef.current.onopen = () => {\n",
        "      console.log('WebSocket is connected.');\n",
        "    };\n",
        "\n",
        "    socketRef.current.onmessage = (event) => {\n",
        "      setTranscriptions((prev) => [...prev, event.data]);\n",
        "    };\n",
        "\n",
        "    socketRef.current.onclose = (event) => {\n",
        "      console.log('WebSocket is closed.', event);\n",
        "    };\n",
        "\n",
        "    socketRef.current.onerror = (error) => {\n",
        "      console.log('WebSocket error:', error);\n",
        "    };\n",
        "  };\n",
        "\n",
        "  useEffect(() => {\n",
        "    setupWebSocket();\n",
        "    return () => {\n",
        "      if (socketRef.current) {\n",
        "        socketRef.current.close();\n",
        "      }\n",
        "    };\n",
        "  }, [websocketUrl]);\n",
        "\n",
        "  return React.createElement(\n",
        "    Container,\n",
        "    null,\n",
        "    React.createElement(\n",
        "      AppBar,\n",
        "      { position: 'static' },\n",
        "      React.createElement(\n",
        "        Toolbar,\n",
        "        null,\n",
        "        React.createElement(Typography, { variant: 'h6' }, \"Audio Recorder\")\n",
        "      )\n",
        "    ),\n",
        "    React.createElement(\n",
        "      Box,\n",
        "      { mt: 2 },\n",
        "      React.createElement(TextField, {\n",
        "        label: \"WebSocket URL\",\n",
        "        variant: \"outlined\",\n",
        "        fullWidth: true,\n",
        "        value: websocketUrl,\n",
        "        onChange: handleWebSocketUrlChange,\n",
        "        style: { marginBottom: 16 }\n",
        "      }),\n",
        "      React.createElement(\n",
        "        Button,\n",
        "        {\n",
        "          variant: 'contained',\n",
        "          color: 'primary',\n",
        "          onClick: handleStartRecording,\n",
        "          disabled: isRecording\n",
        "        },\n",
        "        \"Start Recording\"\n",
        "      ),\n",
        "      React.createElement(\n",
        "        Button,\n",
        "        {\n",
        "          variant: 'contained',\n",
        "          color: 'secondary',\n",
        "          onClick: handleStopRecording,\n",
        "          disabled: !isRecording,\n",
        "          style: { marginLeft: 16 }\n",
        "        },\n",
        "        \"Stop Recording\"\n",
        "      )\n",
        "    ),\n",
        "    React.createElement(\n",
        "      'div',\n",
        "      { className: 'transcription-container' },\n",
        "      transcriptions.map((text, index) =>\n",
        "        React.createElement(\n",
        "          'div',\n",
        "          {\n",
        "            key: index,\n",
        "            className: 'chat-bubble'\n",
        "          },\n",
        "          text\n",
        "        )\n",
        "      )\n",
        "    )\n",
        "  );\n",
        "}\n",
        "\n",
        "ReactDOM.render(\n",
        "  React.createElement(App),\n",
        "  document.getElementById('root')\n",
        ");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJsdKHxPnB7r",
        "outputId": "29da2d2e-d935-43da-9ccd-7f1d7b43d0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing www/app.js\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python 스크립트로 서버 백그라운드에서 실행\n",
        "%%writefile run_server.py\n",
        "import subprocess\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Flask 서버 시작\n",
        "server_process = subprocess.Popen([\"python\", \"app.py\"])\n",
        "print(\"Flask 서버가 시작되었습니다.\")\n",
        "\n",
        "# ngrok 터널 생성\n",
        "http_tunnel = ngrok.connect(3000)\n",
        "print(f\"ngrok 터널이 생성되었습니다: {http_tunnel.public_url}\")\n",
        "\n",
        "try:\n",
        "    # 앱이 계속 실행되도록 대기\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    # 종료 시 프로세스 정리\n",
        "    server_process.terminate()\n",
        "    ngrok.kill()\n",
        "\n",
        "# 이 코드는 Colab이 계속 실행 중일 때만 작동합니다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxQ1QG7_nDWs",
        "outputId": "8b39e283-a906-4988-cafc-7180f624e95e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run_server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_server.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCVpNCEXnTD7",
        "outputId": "b2bfb7b7-8b28-4e5b-e692-930efcb96ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flask 서버가 시작되었습니다.\n",
            "ngrok 터널이 생성되었습니다: https://85c3-34-34-89-80.ngrok-free.app\n",
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 64.7MiB/s]\n",
            " * Serving Flask app 'app'\n",
            " * Debug mode: on\n",
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:3000\n",
            " * Running on http://172.28.0.12:3000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            " * Restarting with stat\n",
            " * Debugger is active!\n",
            " * Debugger PIN: 347-788-323\n",
            "127.0.0.1 - - [27/May/2025 01:56:45] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2025 01:56:45] \"GET /styles.css HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2025 01:56:46] \"GET /app.js HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2025 01:56:46] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/run_server.py\", line 16, in <module>\n",
            "    time.sleep(1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/run_server.py\", line 20, in <module>\n",
            "    ngrok.kill()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\", line 494, in kill\n",
            "    process.kill_process(pyngrok_config.ngrok_path)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\", line 287, in kill_process\n",
            "    ngrok_process.proc.wait()\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 1264, in wait\n",
            "    return self._wait(timeout=timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 2053, in _wait\n",
            "    (pid, sts) = self._try_wait(0)\n",
            "                 ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 2011, in _try_wait\n",
            "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}